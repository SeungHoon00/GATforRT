{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "7599de74",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/hoon/anaconda3/envs/PartitionedRT/lib/python3.8/site-packages/tqdm/auto.py:22: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "# I always like to structure my imports into Python's native libs,\n",
    "# stuff I installed via conda/pip and local file imports (but we don't have those here)\n",
    "\n",
    "import json\n",
    "import os\n",
    "import enum\n",
    "\n",
    "# Visualization related imports\n",
    "import matplotlib.pyplot as plt\n",
    "import networkx as nx\n",
    "from networkx.readwrite import json_graph\n",
    "import igraph as ig\n",
    "from torch.hub import download_url_to_file\n",
    "# Main computation libraries\n",
    "import numpy as np\n",
    "import zipfile\n",
    "# Deep learning related imports\n",
    "import torch\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "\n",
    "import numpy as np\n",
    "import torch\n",
    "from preprocess import Preprocessing\n",
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "31d762eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "    Contains constants needed for data loading and visualization.\n",
    "\n",
    "\"\"\"\n",
    "\n",
    "\n",
    "# Supported datasets - only PPI in this notebook\n",
    "class DatasetType(enum.Enum):\n",
    "    PPI = 0\n",
    "\n",
    "    \n",
    "class GraphVisualizationTool(enum.Enum):\n",
    "    IGRAPH = 0\n",
    "\n",
    "\n",
    "# We'll be dumping and reading the data from this directory\n",
    "DATA_DIR_PATH = os.path.join(os.getcwd(), 'data')\n",
    "PPI_PATH = os.path.join(DATA_DIR_PATH, 'ppi')\n",
    "PPI_URL = 'https://data.dgl.ai/dataset/ppi.zip'  # preprocessed PPI data from Deep Graph Library\n",
    "\n",
    "#\n",
    "# PPI specific constants\n",
    "#\n",
    "\n",
    "PPI_NUM_INPUT_FEATURES = 50\n",
    "PPI_NUM_CLASSES = 121"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "38a901c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# First let's define this simple function for loading PPI's graph data\n",
    "\n",
    "def json_read(path):\n",
    "    with open(path, 'r') as file:\n",
    "        data = json.load(file)\n",
    "\n",
    "    return data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cc68df11",
   "metadata": {},
   "source": [
    "RLforRT Implementation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "60e4c335",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_graph_data(training_config, device):\n",
    "    dataset_name = training_config['dataset_name'].lower()\n",
    "    should_visualize = training_config['should_visualize']\n",
    "\n",
    "    if dataset_name == 'rlforrt':  # RLforRT\n",
    "        \n",
    "        with open('./generated_sets/attr_paper_fbbffd_8proc_500000.pkl', 'rb') as f:\n",
    "            node_features = pickle.load(f)\n",
    "        with open('./generated_sets/weights_paper_fbbffd_8proc_500000.pkl', 'rb') as f:\n",
    "            edge_weights = pickle.load(f)\n",
    "        with open('./generated_sets/fbbffd_sche_paper_fbbffd_8proc_500000.pkl', 'rb') as f:\n",
    "            node_labels = pickle.load(f)\n",
    "        with open('./generated_sets/edge_index_paper_fbbffd_8proc_500000.pkl', 'rb') as f:\n",
    "            edge_index = pickle.load(f)        \n",
    "        \n",
    "        node_features_list = node_features\n",
    "        edge_index_list = edge_index\n",
    "        node_labels_list = node_labels\n",
    "        edge_weights_list = edge_weights\n",
    "\n",
    "        num_graphs_per_split_cumulative = [300000, 310000]\n",
    "        \n",
    "\n",
    "        # Optimization, do a shortcut in case we only need the test data loader\n",
    "        if training_config['ppi_load_test_only']:\n",
    "            data_loader_test = GraphDataLoader(\n",
    "                node_features_list[num_graphs_per_split_cumulative[0]:num_graphs_per_split_cumulative[1]],\n",
    "                node_labels_list[num_graphs_per_split_cumulative[0]:num_graphs_per_split_cumulative[1]],\n",
    "                edge_index_list[num_graphs_per_split_cumulative[0]:num_graphs_per_split_cumulative[1]],\n",
    "                edge_weights_list[num_graphs_per_split_cumulative[0]:num_graphs_per_split_cumulative[1]],\n",
    "                batch_size=10000,\n",
    "                shuffle=False\n",
    "            )\n",
    "            return data_loader_test\n",
    "    else:\n",
    "        raise Exception(f'{dataset_name} not yet supported.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "479db722",
   "metadata": {},
   "outputs": [],
   "source": [
    "class GraphDataLoader(DataLoader):\n",
    "    \"\"\"\n",
    "    When dealing with batches it's always a good idea to inherit from PyTorch's provided classes (Dataset/DataLoader).\n",
    "\n",
    "    \"\"\"\n",
    "    def __init__(self, node_features_list, node_labels_list, edge_index_list, edge_weights_list, batch_size=1, shuffle=False):\n",
    "        graph_dataset = GraphDataset(node_features_list, node_labels_list, edge_index_list, edge_weights_list)\n",
    "        # We need to specify a custom collate function, it doesn't work with the default one\n",
    "        super().__init__(graph_dataset, batch_size, shuffle, collate_fn=graph_collate_fn)\n",
    "\n",
    "\n",
    "class GraphDataset(Dataset):\n",
    "    \"\"\"\n",
    "    This one just fetches a single graph from the split when GraphDataLoader \"asks\" it\n",
    "\n",
    "    \"\"\"\n",
    "    def __init__(self, node_features_list, node_labels_list, edge_index_list, edge_weights_list):\n",
    "        self.node_features_list = node_features_list\n",
    "        self.node_labels_list = node_labels_list\n",
    "        self.edge_index_list = edge_index_list\n",
    "        self.edge_weights_list = edge_weights_list\n",
    "\n",
    "    # 2 interface functions that need to be defined are len and getitem so that DataLoader can do it's magic\n",
    "    def __len__(self):\n",
    "        return len(self.edge_index_list)\n",
    "\n",
    "    def __getitem__(self, idx):  # we just fetch a single graph\n",
    "        return self.node_features_list[idx], self.node_labels_list[idx], self.edge_index_list[idx], self.edge_weights_list[idx]\n",
    "\n",
    "\n",
    "def graph_collate_fn(batch):\n",
    "    \"\"\"\n",
    "    The main idea here is to take multiple graphs from PPI as defined by the batch size\n",
    "    and merge them into a single graph with multiple connected components.\n",
    "\n",
    "    It's important to adjust the node ids in edge indices such that they form a consecutive range. Otherwise\n",
    "    the scatter functions in the implementation 3 will fail.\n",
    "\n",
    "    :param batch: contains a list of edge_index, node_features, node_labels tuples (as provided by the GraphDataset)\n",
    "    \"\"\"\n",
    "\n",
    "    edge_index_list = []\n",
    "    node_features_list = []\n",
    "    node_labels_list = []\n",
    "    edge_weights_list = []\n",
    "    num_nodes_seen = 0\n",
    "\n",
    "    for features_labels_edge_index_tuple in batch:\n",
    "        # Just collect these into separate lists\n",
    "        node_features_list.append(features_labels_edge_index_tuple[0])\n",
    "        node_labels_list.append(features_labels_edge_index_tuple[1])\n",
    "\n",
    "        edge_index = features_labels_edge_index_tuple[2]  # all of the components are in the [0, N] range\n",
    "        edge_weights_list.append(features_labels_edge_index_tuple[3])\n",
    "        edge_index_list.append(edge_index + num_nodes_seen)  # very important! translate the range of this component\n",
    "        num_nodes_seen += len(features_labels_edge_index_tuple[1])  # update the number of nodes we've seen so far\n",
    "    # Merge the PPI graphs into a single graph with multiple connected components\n",
    "    \n",
    "    node_features = torch.cat(node_features_list, 0)\n",
    "    node_labels = torch.cat(node_labels_list, 0)\n",
    "    edge_index = torch.cat(edge_index_list, 1)\n",
    "    edge_weights = torch.cat(edge_weights_list, 0)\n",
    "    \n",
    "    return node_features, node_labels, edge_index, edge_weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "a56fe262",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "********************\n",
      "torch.Size([117729, 4]) torch.float32\n",
      "torch.Size([117729, 8]) torch.float64\n",
      "torch.Size([2, 651247]) torch.int64\n",
      "torch.Size([651247]) torch.float32\n"
     ]
    }
   ],
   "source": [
    "# Let's just define dummy visualization functions for now - just to stop Python interpreter from complaining!\n",
    "# We'll define them in a moment, properly, I swear.\n",
    "\n",
    "def plot_in_out_degree_distributions():\n",
    "    pass\n",
    "\n",
    "def visualize_graph():\n",
    "    pass\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")  # checking whether you have a GPU\n",
    "\n",
    "config = {\n",
    "    'dataset_name': 'RLforRT',\n",
    "    'should_visualize': False,\n",
    "    'batch_size': 1,\n",
    "    'ppi_load_test_only': True  # small optimization for loading test graphs only, we won't use it here\n",
    "}\n",
    "\n",
    "data_loader_test = load_graph_data(config, device)\n",
    "# Let's fetch a single batch from the train graph data loader\n",
    "node_features, node_labels, edge_index, edge_weights = next(iter(data_loader_test))\n",
    "\n",
    "print('*' * 20)\n",
    "print(node_features.shape, node_features.dtype)\n",
    "print(node_labels.shape, node_labels.dtype)\n",
    "print(edge_index.shape, edge_index.dtype)\n",
    "print(edge_weights.shape, edge_weights.dtype)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "b3c448dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "from torch.optim import Adam\n",
    "\n",
    "\n",
    "class GAT(torch.nn.Module):\n",
    "    \"\"\"\n",
    "    The most interesting and hardest implementation is implementation #3.\n",
    "    Imp1 and imp2 differ in subtle details but are basically the same thing.\n",
    "\n",
    "    So I'll focus on imp #3 in this notebook.\n",
    "\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, num_of_layers, num_heads_per_layer, num_features_per_layer, add_skip_connection=True, bias=True,\n",
    "                 dropout=0.6, log_attention_weights=False):\n",
    "        super().__init__()\n",
    "        assert num_of_layers == len(num_heads_per_layer) == len(num_features_per_layer) - 1, f'Enter valid arch params.'\n",
    "\n",
    "        num_heads_per_layer = [1] + num_heads_per_layer  # trick - so that I can nicely create GAT layers below\n",
    "\n",
    "        gat_layers = []  # collect GAT layers\n",
    "        for i in range(num_of_layers):\n",
    "            layer = GATLayer(\n",
    "                num_in_features=num_features_per_layer[i] * num_heads_per_layer[i],  # consequence of concatenation\n",
    "                num_out_features=num_features_per_layer[i+1],\n",
    "                num_of_heads=num_heads_per_layer[i+1],\n",
    "                concat=True if i < num_of_layers - 1 else False,  # last GAT layer does mean avg, the others do concat\n",
    "                activation=nn.ELU() if i < num_of_layers - 1 else None,  # last layer just outputs raw scores\n",
    "                dropout_prob=dropout,\n",
    "                add_skip_connection=add_skip_connection,\n",
    "                bias=bias,\n",
    "                log_attention_weights=log_attention_weights\n",
    "            )\n",
    "            gat_layers.append(layer)\n",
    "\n",
    "        self.gat_net = nn.Sequential(\n",
    "            *gat_layers,\n",
    "        )\n",
    "\n",
    "    # data is just a (in_nodes_features, edge_index) tuple, I had to do it like this because of the nn.Sequential:\n",
    "    # https://discuss.pytorch.org/t/forward-takes-2-positional-arguments-but-3-were-given-for-nn-sqeuential-with-linear-layers/65698\n",
    "    def forward(self, data):\n",
    "        return self.gat_net(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "7af2ed27",
   "metadata": {},
   "outputs": [],
   "source": [
    "class GATLayer(torch.nn.Module):\n",
    "    \"\"\"\n",
    "    Implementation #3 was inspired by PyTorch Geometric: https://github.com/rusty1s/pytorch_geometric\n",
    "\n",
    "    But, it's hopefully much more readable! (and of similar performance)\n",
    "\n",
    "    \"\"\"\n",
    "    \n",
    "    # We'll use these constants in many functions so just extracting them here as member fields\n",
    "    src_nodes_dim = 0  # position of source nodes in edge index\n",
    "    trg_nodes_dim = 1  # position of target nodes in edge index\n",
    "\n",
    "    # These may change in the inductive setting - leaving it like this for now (not future proof)\n",
    "    nodes_dim = 0      # node dimension (axis is maybe a more familiar term nodes_dim is the position of \"N\" in tensor)\n",
    "    head_dim = 1       # attention head dim\n",
    "\n",
    "    def __init__(self, num_in_features, num_out_features, num_of_heads, concat=True, activation=nn.ELU(),\n",
    "                 dropout_prob=0.6, add_skip_connection=True, bias=True, log_attention_weights=False):\n",
    "\n",
    "        super().__init__()\n",
    "\n",
    "        self.num_of_heads = num_of_heads\n",
    "        self.num_out_features = num_out_features\n",
    "        self.concat = concat  # whether we should concatenate or average the attention heads\n",
    "        self.add_skip_connection = add_skip_connection\n",
    "\n",
    "        #\n",
    "        # Trainable weights: linear projection matrix (denoted as \"W\" in the paper), attention target/source\n",
    "        # (denoted as \"a\" in the paper) and bias (not mentioned in the paper but present in the official GAT repo)\n",
    "        #\n",
    "\n",
    "        # You can treat this one matrix as num_of_heads independent W matrices\n",
    "        self.linear_proj = nn.Linear(num_in_features, num_of_heads * num_out_features, bias=False)\n",
    "\n",
    "        # After we concatenate target node (node i) and source node (node j) we apply the \"additive\" scoring function\n",
    "        # which gives us un-normalized score \"e\". Here we split the \"a\" vector - but the semantics remain the same.\n",
    "        # Basically instead of doing [x, y] (concatenation, x/y are node feature vectors) and dot product with \"a\"\n",
    "        # we instead do a dot product between x and \"a_left\" and y and \"a_right\" and we sum them up\n",
    "        self.scoring_fn_target = nn.Parameter(torch.Tensor(1, num_of_heads, num_out_features))\n",
    "        self.scoring_fn_source = nn.Parameter(torch.Tensor(1, num_of_heads, num_out_features))\n",
    "\n",
    "        # Bias is definitely not crucial to GAT - feel free to experiment (I pinged the main author, Petar, on this one)\n",
    "        if bias and concat:\n",
    "            self.bias = nn.Parameter(torch.Tensor(num_of_heads * num_out_features))\n",
    "        elif bias and not concat:\n",
    "            self.bias = nn.Parameter(torch.Tensor(num_out_features))\n",
    "        else:\n",
    "            self.register_parameter('bias', None)\n",
    "\n",
    "        if add_skip_connection:\n",
    "            self.skip_proj = nn.Linear(num_in_features, num_of_heads * num_out_features, bias=False)\n",
    "        else:\n",
    "            self.register_parameter('skip_proj', None)\n",
    "\n",
    "        #\n",
    "        # End of trainable weights\n",
    "        #\n",
    "\n",
    "        self.leakyReLU = nn.LeakyReLU(0.2)  # using 0.2 as in the paper, no need to expose every setting\n",
    "        self.activation = activation\n",
    "        # Probably not the nicest design but I use the same module in 3 locations, before/after features projection\n",
    "        # and for attention coefficients. Functionality-wise it's the same as using independent modules.\n",
    "        self.dropout = nn.Dropout(p=dropout_prob)\n",
    "\n",
    "        self.log_attention_weights = log_attention_weights  # whether we should log the attention weights\n",
    "        self.attention_weights = None  # for later visualization purposes, I cache the weights here\n",
    "\n",
    "        self.init_params()\n",
    "        \n",
    "    def forward(self, data):\n",
    "        #\n",
    "        # Step 1: Linear Projection + regularization\n",
    "        #\n",
    "\n",
    "        in_nodes_features, edge_index, edge_weights = data  # unpack data\n",
    "        \n",
    "        num_edge_weights = edge_weights.shape[0]\n",
    "        scores_edge_weights = edge_weights.repeat(self.num_of_heads, 1)\n",
    "        scores_edge_weights = torch.swapaxes(scores_edge_weights, 0, 1)\n",
    "        \n",
    "        num_of_nodes = in_nodes_features.shape[self.nodes_dim]\n",
    "        #assert edge_index.shape[0] == 2, f'Expected edge index with shape=(2,E) got {edge_index.shape}'\n",
    "\n",
    "        # shape = (N, FIN) where N - number of nodes in the graph, FIN - number of input features per node\n",
    "        # We apply the dropout to all of the input node features (as mentioned in the paper)\n",
    "        in_nodes_features = self.dropout(in_nodes_features)\n",
    "\n",
    "        # shape = (N, FIN) * (FIN, NH*FOUT) -> (N, NH, FOUT) where NH - number of heads, FOUT - num of output features\n",
    "        # We project the input node features into NH independent output features (one for each attention head)\n",
    "        nodes_features_proj = self.linear_proj(in_nodes_features).view(-1, self.num_of_heads, self.num_out_features)\n",
    "\n",
    "        nodes_features_proj = self.dropout(nodes_features_proj)  # in the official GAT imp they did dropout here as well\n",
    "\n",
    "        #\n",
    "        # Step 2: Edge attention calculation\n",
    "        #\n",
    "\n",
    "        # Apply the scoring function (* represents element-wise (a.k.a. Hadamard) product)\n",
    "        # shape = (N, NH, FOUT) * (1, NH, FOUT) -> (N, NH, 1) -> (N, NH) because sum squeezes the last dimension\n",
    "        # Optimization note: torch.sum() is as performant as .sum() in my experiments\n",
    "        scores_source = (nodes_features_proj * self.scoring_fn_source).sum(dim=-1)\n",
    "        scores_target = (nodes_features_proj * self.scoring_fn_target).sum(dim=-1)\n",
    "        #print(\"scoring_fn_source : \", self.scoring_fn_source)\n",
    "        #print(\"Scores source : \", scores_source.shape)\n",
    "        #print(\"Scores target : \", scores_target.shape)\n",
    "\n",
    "        # We simply copy (lift) the scores for source/target nodes based on the edge index. Instead of preparing all\n",
    "        # the possible combinations of scores we just prepare those that will actually be used and those are defined\n",
    "        # by the edge index.\n",
    "        # scores shape = (E, NH), nodes_features_proj_lifted shape = (E, NH, FOUT), E - number of edges in the graph\n",
    "        scores_source_lifted, scores_target_lifted, nodes_features_proj_lifted = self.lift(scores_source, scores_target, nodes_features_proj, edge_index)\n",
    "        #scores_per_edge = self.leakyReLU(scores_source_lifted + scores_target_lifted)\n",
    "        scores_per_edge = self.leakyReLU(scores_source_lifted + scores_target_lifted + scores_edge_weights)\n",
    "        \n",
    "        # shape = (E, NH, 1)\n",
    "        attentions_per_edge = self.neighborhood_aware_softmax(scores_per_edge, edge_index[self.trg_nodes_dim], num_of_nodes)\n",
    "        # Add stochasticity to neighborhood aggregation\n",
    "        attentions_per_edge = self.dropout(attentions_per_edge)\n",
    "\n",
    "        #\n",
    "        # Step 3: Neighborhood aggregation\n",
    "        #\n",
    "\n",
    "        # Element-wise (aka Hadamard) product. Operator * does the same thing as torch.mul\n",
    "        # shape = (E, NH, FOUT) * (E, NH, 1) -> (E, NH, FOUT), 1 gets broadcast into FOUT\n",
    "        nodes_features_proj_lifted_weighted = nodes_features_proj_lifted * attentions_per_edge\n",
    "\n",
    "        # This part sums up weighted and projected neighborhood feature vectors for every target node\n",
    "        # shape = (N, NH, FOUT)\n",
    "        out_nodes_features = self.aggregate_neighbors(nodes_features_proj_lifted_weighted, edge_index, in_nodes_features, num_of_nodes)\n",
    "\n",
    "        #\n",
    "        # Step 4: Residual/skip connections, concat and bias\n",
    "        #\n",
    "\n",
    "        out_nodes_features = self.skip_concat_bias(attentions_per_edge, in_nodes_features, out_nodes_features)\n",
    "        return (out_nodes_features, edge_index, edge_weights)\n",
    "\n",
    "    #\n",
    "    # Helper functions (without comments there is very little code so don't be scared!)\n",
    "    #\n",
    "\n",
    "    def neighborhood_aware_softmax(self, scores_per_edge, trg_index, num_of_nodes):\n",
    "        \"\"\"\n",
    "        As the fn name suggest it does softmax over the neighborhoods. Example: say we have 5 nodes in a graph.\n",
    "        Two of them 1, 2 are connected to node 3. If we want to calculate the representation for node 3 we should take\n",
    "        into account feature vectors of 1, 2 and 3 itself. Since we have scores for edges 1-3, 2-3 and 3-3\n",
    "        in scores_per_edge variable, this function will calculate attention scores like this: 1-3/(1-3+2-3+3-3)\n",
    "        (where 1-3 is overloaded notation it represents the edge 1-3 and its (exp) score) and similarly for 2-3 and 3-3\n",
    "         i.e. for this neighborhood we don't care about other edge scores that include nodes 4 and 5.\n",
    "\n",
    "        Note:\n",
    "        Subtracting the max value from logits doesn't change the end result but it improves the numerical stability\n",
    "        and it's a fairly common \"trick\" used in pretty much every deep learning framework.\n",
    "        Check out this link for more details:\n",
    "\n",
    "        https://stats.stackexchange.com/questions/338285/how-does-the-subtraction-of-the-logit-maximum-improve-learning\n",
    "\n",
    "        \"\"\"\n",
    "        # Calculate the numerator. Make logits <= 0 so that e^logit <= 1 (this will improve the numerical stability)\n",
    "        scores_per_edge = scores_per_edge - scores_per_edge.max()\n",
    "        exp_scores_per_edge = scores_per_edge.exp()  # softmax\n",
    "\n",
    "        # Calculate the denominator. shape = (E, NH)\n",
    "        neigborhood_aware_denominator = self.sum_edge_scores_neighborhood_aware(exp_scores_per_edge, trg_index, num_of_nodes)\n",
    "\n",
    "        # 1e-16 is theoretically not needed but is only there for numerical stability (avoid div by 0) - due to the\n",
    "        # possibility of the computer rounding a very small number all the way to 0.\n",
    "        attentions_per_edge = exp_scores_per_edge / (neigborhood_aware_denominator + 1e-16)\n",
    "\n",
    "        # shape = (E, NH) -> (E, NH, 1) so that we can do element-wise multiplication with projected node features\n",
    "        return attentions_per_edge.unsqueeze(-1)\n",
    "\n",
    "    def sum_edge_scores_neighborhood_aware(self, exp_scores_per_edge, trg_index, num_of_nodes):\n",
    "        # The shape must be the same as in exp_scores_per_edge (required by scatter_add_) i.e. from E -> (E, NH)\n",
    "        trg_index_broadcasted = self.explicit_broadcast(trg_index, exp_scores_per_edge)\n",
    "\n",
    "        # shape = (N, NH), where N is the number of nodes and NH the number of attention heads\n",
    "        size = list(exp_scores_per_edge.shape)  # convert to list otherwise assignment is not possible\n",
    "        size[self.nodes_dim] = num_of_nodes\n",
    "        neighborhood_sums = torch.zeros(size, dtype=exp_scores_per_edge.dtype, device=exp_scores_per_edge.device)\n",
    "\n",
    "        # position i will contain a sum of exp scores of all the nodes that point to the node i (as dictated by the\n",
    "        # target index)\n",
    "        neighborhood_sums.scatter_add_(self.nodes_dim, trg_index_broadcasted, exp_scores_per_edge)\n",
    "\n",
    "        # Expand again so that we can use it as a softmax denominator. e.g. node i's sum will be copied to\n",
    "        # all the locations where the source nodes pointed to i (as dictated by the target index)\n",
    "        # shape = (N, NH) -> (E, NH)\n",
    "        return neighborhood_sums.index_select(self.nodes_dim, trg_index)\n",
    "\n",
    "    def aggregate_neighbors(self, nodes_features_proj_lifted_weighted, edge_index, in_nodes_features, num_of_nodes):\n",
    "        size = list(nodes_features_proj_lifted_weighted.shape)  # convert to list otherwise assignment is not possible\n",
    "        size[self.nodes_dim] = num_of_nodes  # shape = (N, NH, FOUT)\n",
    "        out_nodes_features = torch.zeros(size, dtype=in_nodes_features.dtype, device=in_nodes_features.device)\n",
    "\n",
    "        # shape = (E) -> (E, NH, FOUT)\n",
    "        trg_index_broadcasted = self.explicit_broadcast(edge_index[self.trg_nodes_dim], nodes_features_proj_lifted_weighted)\n",
    "        # aggregation step - we accumulate projected, weighted node features for all the attention heads\n",
    "        # shape = (E, NH, FOUT) -> (N, NH, FOUT)\n",
    "        out_nodes_features.scatter_add_(self.nodes_dim, trg_index_broadcasted, nodes_features_proj_lifted_weighted)\n",
    "\n",
    "        return out_nodes_features\n",
    "\n",
    "    def lift(self, scores_source, scores_target, nodes_features_matrix_proj, edge_index):\n",
    "        \"\"\"\n",
    "        Lifts i.e. duplicates certain vectors depending on the edge index.\n",
    "        One of the tensor dims goes from N -> E (that's where the \"lift\" comes from).\n",
    "\n",
    "        \"\"\"\n",
    "        src_nodes_index = edge_index[self.src_nodes_dim]\n",
    "        trg_nodes_index = edge_index[self.trg_nodes_dim]\n",
    "\n",
    "        # Using index_select is faster than \"normal\" indexing (scores_source[src_nodes_index]) in PyTorch!\n",
    "        scores_source = scores_source.index_select(self.nodes_dim, src_nodes_index)\n",
    "        scores_target = scores_target.index_select(self.nodes_dim, trg_nodes_index)\n",
    "        nodes_features_matrix_proj_lifted = nodes_features_matrix_proj.index_select(self.nodes_dim, src_nodes_index)\n",
    "\n",
    "        return scores_source, scores_target, nodes_features_matrix_proj_lifted\n",
    "\n",
    "    def explicit_broadcast(self, this, other):\n",
    "        # Append singleton dimensions until this.dim() == other.dim()\n",
    "        for _ in range(this.dim(), other.dim()):\n",
    "            this = this.unsqueeze(-1)\n",
    "\n",
    "        # Explicitly expand so that shapes are the same\n",
    "        return this.expand_as(other)\n",
    "\n",
    "    def init_params(self):\n",
    "        \"\"\"\n",
    "        The reason we're using Glorot (aka Xavier uniform) initialization is because it's a default TF initialization:\n",
    "            https://stackoverflow.com/questions/37350131/what-is-the-default-variable-initializer-in-tensorflow\n",
    "\n",
    "        The original repo was developed in TensorFlow (TF) and they used the default initialization.\n",
    "        Feel free to experiment - there may be better initializations depending on your problem.\n",
    "\n",
    "        \"\"\"\n",
    "        nn.init.xavier_uniform_(self.linear_proj.weight)\n",
    "        nn.init.xavier_uniform_(self.scoring_fn_target)\n",
    "        nn.init.xavier_uniform_(self.scoring_fn_source)\n",
    "\n",
    "        if self.bias is not None:\n",
    "            torch.nn.init.zeros_(self.bias)\n",
    "\n",
    "    def skip_concat_bias(self, attention_coefficients, in_nodes_features, out_nodes_features):\n",
    "        if self.log_attention_weights:  # potentially log for later visualization in playground.py\n",
    "            self.attention_weights = attention_coefficients\n",
    "\n",
    "        if self.add_skip_connection:  # add skip or residual connection\n",
    "            if out_nodes_features.shape[-1] == in_nodes_features.shape[-1]:  # if FIN == FOUT\n",
    "                # unsqueeze does this: (N, FIN) -> (N, 1, FIN), out features are (N, NH, FOUT) so 1 gets broadcast to NH\n",
    "                # thus we're basically copying input vectors NH times and adding to processed vectors\n",
    "                out_nodes_features += in_nodes_features.unsqueeze(1)\n",
    "            else:\n",
    "                # FIN != FOUT so we need to project input feature vectors into dimension that can be added to output\n",
    "                # feature vectors. skip_proj adds lots of additional capacity which may cause overfitting.\n",
    "                out_nodes_features += self.skip_proj(in_nodes_features).view(-1, self.num_of_heads, self.num_out_features)\n",
    "\n",
    "        if self.concat:\n",
    "            # shape = (N, NH, FOUT) -> (N, NH*FOUT)\n",
    "            out_nodes_features = out_nodes_features.view(-1, self.num_of_heads * self.num_out_features)\n",
    "        else:\n",
    "            # shape = (N, NH, FOUT) -> (N, FOUT)\n",
    "            out_nodes_features = out_nodes_features.mean(dim=self.head_dim)\n",
    "\n",
    "        if self.bias is not None:\n",
    "            out_nodes_features += self.bias\n",
    "\n",
    "        return out_nodes_features if self.activation is None else self.activation(out_nodes_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "b171dd4c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#from torch.utils.tensorboard import SummaryWriter\n",
    "\n",
    "\n",
    "# 3 different model training/eval phases used in train.py\n",
    "class LoopPhase(enum.Enum):\n",
    "    TRAIN = 0,\n",
    "    VAL = 1,\n",
    "    TEST = 2\n",
    "\n",
    "    \n",
    "#writer = SummaryWriter()  # (tensorboard) writer will output to ./runs/ directory by default\n",
    "\n",
    "\n",
    "# Global vars used for early stopping. After some number of epochs (as defined by the patience_period var) without any\n",
    "# improvement on the validation dataset (measured via micro-F1 metric), we'll break out from the training loop.\n",
    "BEST_VAL_MICRO_F1 = 0\n",
    "BEST_VAL_LOSS = 0\n",
    "PATIENCE_CNT = 0\n",
    "\n",
    "BINARIES_PATH = os.path.join(os.getcwd(), 'models', 'binaries')\n",
    "CHECKPOINTS_PATH = os.path.join(os.getcwd(), 'models', 'checkpoints')\n",
    "\n",
    "# Make sure these exist as the rest of the code assumes it\n",
    "os.makedirs(BINARIES_PATH, exist_ok=True)\n",
    "os.makedirs(CHECKPOINTS_PATH, exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "e78b4f46",
   "metadata": {},
   "outputs": [],
   "source": [
    "import git\n",
    "import re  # regex\n",
    "\n",
    "\n",
    "def get_training_state(training_config, model):\n",
    "    training_state = {\n",
    "        #\"commit_hash\": git.Repo(search_parent_directories=True).head.object.hexsha,\n",
    "\n",
    "        # Training details\n",
    "        \"dataset_name\": training_config['dataset_name'],\n",
    "        \"num_of_epochs\": training_config['num_of_epochs'],\n",
    "        \"test_perf\": training_config['test_perf'],\n",
    "\n",
    "        # Model structure\n",
    "        \"num_of_layers\": training_config['num_of_layers'],\n",
    "        \"num_heads_per_layer\": training_config['num_heads_per_layer'],\n",
    "        \"num_features_per_layer\": training_config['num_features_per_layer'],\n",
    "        \"add_skip_connection\": training_config['add_skip_connection'],\n",
    "        \"bias\": training_config['bias'],\n",
    "        \"dropout\": training_config['dropout'],\n",
    "\n",
    "        # Model state\n",
    "        \"state_dict\": model.state_dict()\n",
    "    }\n",
    "\n",
    "    return training_state\n",
    "\n",
    "\n",
    "def print_model_metadata(training_state):\n",
    "    header = f'\\n{\"*\"*5} Model training metadata: {\"*\"*5}'\n",
    "    print(header)\n",
    "\n",
    "    for key, value in training_state.items():\n",
    "        if key != 'state_dict':  # don't print state_dict it's a bunch of numbers...\n",
    "            print(f'{key}: {value}')\n",
    "    print(f'{\"*\" * len(header)}\\n')\n",
    "    \n",
    "\n",
    "# This one makes sure we don't overwrite the valuable model binaries (feel free to ignore - not crucial to GAT method)\n",
    "def get_available_binary_name(dataset_name='unknown'):\n",
    "    prefix = f'gat_{dataset_name}'\n",
    "\n",
    "    def valid_binary_name(binary_name):\n",
    "        # First time you see raw f-string? Don't worry the only trick is to double the brackets.\n",
    "        pattern = re.compile(rf'16proc_{prefix}_[0-9]{{6}}\\.pth')\n",
    "        return re.fullmatch(pattern, binary_name) is not None\n",
    "\n",
    "    # Just list the existing binaries so that we don't overwrite them but write to a new one\n",
    "    valid_binary_names = list(filter(valid_binary_name, os.listdir(BINARIES_PATH)))\n",
    "    if len(valid_binary_names) > 0:\n",
    "        last_binary_name = sorted(valid_binary_names)[-1]\n",
    "        new_suffix = int(last_binary_name.split('.')[0][-6:]) + 1  # increment by 1\n",
    "        return f'8proc_{prefix}_{str(new_suffix).zfill(6)}.pth'\n",
    "    else:\n",
    "        return f'8proc_{prefix}_000000.pth'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "124a280c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import argparse\n",
    "\n",
    "NUM_INPUT_FEATURES = 4\n",
    "NUM_CLASSES = 8\n",
    "\n",
    "def get_training_args():\n",
    "    parser = argparse.ArgumentParser()\n",
    "\n",
    "    # Training related\n",
    "    parser.add_argument(\"--num_of_epochs\", type=int, help=\"number of training epochs\", default=200)\n",
    "    parser.add_argument(\"--patience_period\", type=int, help=\"number of epochs with no improvement on val before terminating\", default=100)\n",
    "    parser.add_argument(\"--lr\", type=float, help=\"model learning rate\", default=5e-3)\n",
    "    parser.add_argument(\"--weight_decay\", type=float, help=\"L2 regularization on model weights\", default=0)\n",
    "    parser.add_argument(\"--should_test\", type=bool, help='should test the model on the test dataset?', default=True)\n",
    "    parser.add_argument(\"--force_cpu\", type=bool, help='use CPU if your GPU is too small', default=False)\n",
    "\n",
    "    # Dataset related (note: we need the dataset name for metadata and related stuff, and not for picking the dataset)\n",
    "    parser.add_argument(\"--dataset_name\", choices=[el.name for el in DatasetType], help='dataset to use for training', default='RLforRT')\n",
    "    parser.add_argument(\"--batch_size\", type=int, help='number of graphs in a batch', default=100)\n",
    "    parser.add_argument(\"--should_visualize\", type=bool, help='should visualize the dataset?', default=False)\n",
    "\n",
    "    # Logging/debugging/checkpoint related (helps a lot with experimentation)\n",
    "    parser.add_argument(\"--enable_tensorboard\", type=bool, help=\"enable tensorboard logging\", default=False)\n",
    "    parser.add_argument(\"--console_log_freq\", type=int, help=\"log to output console (epoch) freq (None for no logging)\", default=10)\n",
    "    parser.add_argument(\"--checkpoint_freq\", type=int, help=\"checkpoint model saving (epoch) freq (None for no logging)\", default=5)\n",
    "    args = parser.parse_args('')\n",
    "\n",
    "    # I'm leaving the hyperparam values as reported in the paper, but I experimented a bit and the comments suggest\n",
    "    # how you can make GAT achieve an even higher micro-F1 or make it smaller\n",
    "    gat_config = {\n",
    "        # GNNs, contrary to CNNs, are often shallow (it ultimately depends on the graph properties)\n",
    "        \"num_of_layers\": 3,  # PPI has got 42% of nodes with all 0 features - that's why 3 layers are useful\n",
    "        \"num_heads_per_layer\": [9, 9, 32],  # other values may give even better results from the reported ones\n",
    "        \"num_features_per_layer\": [NUM_INPUT_FEATURES, 64, 64, NUM_CLASSES],  # 64 would also give ~0.975 uF1!\n",
    "        \"add_skip_connection\": True,  # skip connection is very important! (keep it otherwise micro-F1 is almost 0)\n",
    "        \"bias\": True,  # bias doesn't matter that much\n",
    "        \"dropout\": 0.0,  # dropout hurts the performance (best to keep it at 0)\n",
    "    }\n",
    "\n",
    "    # Wrapping training configuration into a dictionary\n",
    "    training_config = dict()\n",
    "    for arg in vars(args):\n",
    "        training_config[arg] = getattr(args, arg)\n",
    "    training_config['ppi_load_test_only'] = True  # load both train/val/test data loaders (don't change it)\n",
    "\n",
    "    # Add additional config information\n",
    "    training_config.update(gat_config)\n",
    "\n",
    "    return training_config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "34198895",
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "\n",
    "\n",
    "def train_gat_rlforrt(config):\n",
    "    \"\"\"\n",
    "    Very similar to Cora's training script. The main differences are:\n",
    "    1. Using dataloaders since we're dealing with an inductive setting - multiple graphs per batch\n",
    "    2. Doing multi-class classification (BCEWithLogitsLoss) and reporting micro-F1 instead of accuracy\n",
    "    3. Model architecture and hyperparams are a bit different (as reported in the GAT paper)\n",
    "\n",
    "    \"\"\"\n",
    "    global BEST_VAL_MICRO_F1, BEST_VAL_LOSS\n",
    " \n",
    "    # Checking whether you have a strong GPU. Since PPI training requires almost 8 GBs of VRAM\n",
    "    # I've added the option to force the use of CPU even though you have a GPU on your system (but it's too weak).\n",
    "    device = torch.device(\"cuda\" if torch.cuda.is_available() and not config['force_cpu'] else \"cpu\")\n",
    "\n",
    "    # Step 1: prepare the data loaders\n",
    "    data_loader_train, data_loader_val, data_loader_test = load_graph_data(config, device)\n",
    "\n",
    "    # Step 2: prepare the model\n",
    "    gat = GAT(\n",
    "        num_of_layers=config['num_of_layers'],\n",
    "        num_heads_per_layer=config['num_heads_per_layer'],\n",
    "        num_features_per_layer=config['num_features_per_layer'],\n",
    "        add_skip_connection=config['add_skip_connection'],\n",
    "        bias=config['bias'],\n",
    "        dropout=config['dropout'],\n",
    "        log_attention_weights=False  # no need to store attentions, used only in playground.py for visualizations\n",
    "    ).to(device)\n",
    "\n",
    "    # Step 3: Prepare other training related utilities (loss & optimizer and decorator function)\n",
    "    loss_fn = nn.BCEWithLogitsLoss(reduction='mean')\n",
    "    optimizer = Adam(gat.parameters(), lr=config['lr'], weight_decay=config['weight_decay'])\n",
    "\n",
    "    # The decorator function makes things cleaner since there is a lot of redundancy between the train and val loops\n",
    "    main_loop = get_main_loop(\n",
    "        config,\n",
    "        gat,\n",
    "        loss_fn,\n",
    "        optimizer,\n",
    "        config['patience_period'],\n",
    "        time.time())\n",
    "\n",
    "    BEST_VAL_MICRO_F1, BEST_VAL_LOSS, PATIENCE_CNT = [0, 0, 0]  # reset vars used for early stopping\n",
    "\n",
    "    # Step 4: Start the training procedure\n",
    "    for epoch in range(config['num_of_epochs']):\n",
    "        # Training loop\n",
    "        main_loop(phase=LoopPhase.TRAIN, data_loader=data_loader_train, epoch=epoch)\n",
    "\n",
    "        # Validation loop\n",
    "        with torch.no_grad():\n",
    "            try:\n",
    "                main_loop(phase=LoopPhase.VAL, data_loader=data_loader_val, epoch=epoch)\n",
    "            except Exception as e:  # \"patience has run out\" exception :O\n",
    "                print(str(e))\n",
    "                break  # break out from the training loop\n",
    "\n",
    "    # Step 5: Potentially test your model\n",
    "    # Don't overfit to the test dataset - only when you've fine-tuned your model on the validation dataset should you\n",
    "    # report your final loss and micro-F1 on the test dataset. Friends don't let friends overfit to the test data. <3\n",
    "    if config['should_test']:\n",
    "            \n",
    "        micro_f1 = main_loop(phase=LoopPhase.TEST, data_loader=data_loader_test, epoch=epoch)\n",
    "        config['test_perf'] = micro_f1\n",
    "\n",
    "        print('*' * 50)\n",
    "        print(f'Test micro-F1 = {micro_f1}')\n",
    "    else:\n",
    "        config['test_perf'] = -1\n",
    "\n",
    "    # Save the latest GAT in the binaries directory\n",
    "    torch.save(\n",
    "        get_training_state(config, gat),\n",
    "        os.path.join(BINARIES_PATH, get_available_binary_name(config['dataset_name']))\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "25bf53f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_gat_rlforrt(config):\n",
    "    \"\"\"\n",
    "    Very similar to Cora's training script. The main differences are:\n",
    "    1. Using dataloaders since we're dealing with an inductive setting - multiple graphs per batch\n",
    "    2. Doing multi-class classification (BCEWithLogitsLoss) and reporting micro-F1 instead of accuracy\n",
    "    3. Model architecture and hyperparams are a bit different (as reported in the GAT paper)\n",
    "\n",
    "    \"\"\"\n",
    "    global BEST_VAL_MICRO_F1, BEST_VAL_LOSS\n",
    " \n",
    "    # Checking whether you have a strong GPU. Since PPI training requires almost 8 GBs of VRAM\n",
    "    # I've added the option to force the use of CPU even though you have a GPU on your system (but it's too weak).\n",
    "    device = torch.device(\"cuda\" if torch.cuda.is_available() and not config['force_cpu'] else \"cpu\")\n",
    "\n",
    "    # Step 1: prepare the data loaders\n",
    "    data_loader_test = load_graph_data(config, device)\n",
    "\n",
    "    # Step 2: prepare the model\n",
    "    gat = GAT(\n",
    "        num_of_layers=config['num_of_layers'],\n",
    "        num_heads_per_layer=config['num_heads_per_layer'],\n",
    "        num_features_per_layer=config['num_features_per_layer'],\n",
    "        add_skip_connection=config['add_skip_connection'],\n",
    "        bias=config['bias'],\n",
    "        dropout=config['dropout'],\n",
    "        log_attention_weights=False  # no need to store attentions, used only in playground.py for visualizations\n",
    "    ).to(device)\n",
    "\n",
    "    # Step 3: Prepare other training related utilities (loss & optimizer and decorator function)\n",
    "    loss_fn = nn.BCEWithLogitsLoss(reduction='mean')\n",
    "    optimizer = Adam(gat.parameters(), lr=config['lr'], weight_decay=config['weight_decay'])\n",
    "\n",
    "    # The decorator function makes things cleaner since there is a lot of redundancy between the train and val loops\n",
    "    main_loop = get_main_loop(\n",
    "        config,\n",
    "        gat,\n",
    "        loss_fn,\n",
    "        optimizer,\n",
    "        config['patience_period'],\n",
    "        time.time())\n",
    "\n",
    "    BEST_VAL_MICRO_F1, BEST_VAL_LOSS, PATIENCE_CNT = [0, 0, 0]  # reset vars used for early stopping\n",
    "\n",
    "    # Step 5: Potentially test your model\n",
    "    # Don't overfit to the test dataset - only when you've fine-tuned your model on the validation dataset should you\n",
    "    torch.load('./models/binaries/8proc_gat_RLforRT_000012.pth', map_location=device)\n",
    "            \n",
    "    micro_f1 = main_loop(phase=LoopPhase.TEST, data_loader=data_loader_test, epoch=10000)\n",
    "    config['test_perf'] = micro_f1\n",
    "\n",
    "    print('*' * 50)\n",
    "    print(f'Test micro-F1 = {micro_f1}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "73df9fdf",
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "\n",
    "\n",
    "def rmrta(tasks, taskorder, num_processor):\n",
    "\n",
    "    bin_pack = [[] for i in range(num_processor)]\n",
    "\n",
    "    for i in range(len(tasks)):\n",
    "        bin_pack[taskorder[i]].append(tasks[i])\n",
    "\n",
    "    unschedulable = False\n",
    "    #print(bin_pack)\n",
    "    for i in range(num_processor):\n",
    "        a, a_past = 0, -1\n",
    "\n",
    "        if not (bin_pack[i]):\n",
    "            continue\n",
    "        while a != a_past:\n",
    "            cal_a = 0\n",
    "            if a == 0:\n",
    "                for j in range(len(bin_pack[i])):\n",
    "                    a += bin_pack[i][j][1]\n",
    "            cal_a = bin_pack[i][len(bin_pack[i])-1][1]\n",
    "\n",
    "            for j in range(len(bin_pack[i])-1):\n",
    "                cal_a += math.ceil(a/bin_pack[i][j][0])*bin_pack[i][j][1]\n",
    "            a_past = a\n",
    "            a = cal_a\n",
    "            if (a > bin_pack[i][len(bin_pack[i])-1][0]):\n",
    "                unschedulable = True\n",
    "                break\n",
    "\n",
    "    return(unschedulable)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "c2483094",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import f1_score\n",
    "\n",
    "\n",
    "# Simple decorator function so that I don't have to pass arguments that don't change from epoch to epoch\n",
    "def get_main_loop(config, gat, sigmoid_cross_entropy_loss, optimizer, patience_period, time_start):\n",
    "\n",
    "    device = next(gat.parameters()).device  # fetch the device info from the model instead of passing it as a param\n",
    "\n",
    "    def main_loop(phase, data_loader, epoch=0):\n",
    "        global BEST_VAL_MICRO_F1, BEST_VAL_LOSS, PATIENCE_CNT, writer\n",
    "\n",
    "        # Certain modules behave differently depending on whether we're training the model or not.\n",
    "        # e.g. nn.Dropout - we only want to drop model weights during the training.\n",
    "        if phase == LoopPhase.TRAIN:\n",
    "            gat.train()\n",
    "        else:\n",
    "            gat.eval()\n",
    "        # Iterate over batches of graph data (2 graphs per batch was used in the original paper for the PPI dataset)\n",
    "        # We merge them into a single graph with 2 connected components, that's the main idea. After that\n",
    "        # the implementation #3 is agnostic to the fact that those are multiple and not a single graph!\n",
    "        for batch_idx, (node_features, gt_node_labels, edge_index, edge_weights) in enumerate(data_loader):\n",
    "            # Push the batch onto GPU - note PPI is to big to load the whole dataset into a normal GPU\n",
    "            # it takes almost 8 GBs of VRAM to train it on a GPU\n",
    "            edge_index = edge_index.to(device)\n",
    "            node_features = node_features.to(device)\n",
    "            gt_node_labels = gt_node_labels.to(device)\n",
    "            edge_weights = edge_weights.to(device)\n",
    "\n",
    "            # I pack data into tuples because GAT uses nn.Sequential which expects this format\n",
    "            graph_data = (node_features, edge_index, edge_weights)\n",
    "\n",
    "            # Note: [0] just extracts the node_features part of the data (index 1 contains the edge_index)\n",
    "            # shape = (N, C) where N is the number of nodes in the batch and C is the number of classes (121 for PPI)\n",
    "            # GAT imp #3 is agnostic to the fact that we actually have multiple graphs\n",
    "            # (it sees a single graph with multiple connected components)\n",
    "            nodes_unnormalized_scores = gat(graph_data)[0]\n",
    "            \n",
    "            \n",
    "            # Example: because PPI has 121 labels let's make a simple toy example that will show how the loss works.\n",
    "            # Let's say we have 3 labels instead and a single node's unnormalized (raw GAT output) scores are [-3, 0, 3]\n",
    "            # What this loss will do is first it will apply a sigmoid and so we'll end up with: [0.048, 0.5, 0.95]\n",
    "            # next it will apply a binary cross entropy across all of these and find the average, and that's it!\n",
    "            # So if the true classes were [0, 0, 1] the loss would be (-log(1-0.048) + -log(1-0.5) + -log(0.95))/3.\n",
    "            # You can see that the logarithm takes 2 forms depending on whether the true label is 0 or 1,\n",
    "            # either -log(1-x) or -log(x) respectively. Easy-peasy. <3\n",
    "            if phase == LoopPhase.TRAIN:\n",
    "                loss = sigmoid_cross_entropy_loss(nodes_unnormalized_scores, gt_node_labels)\n",
    "            elif phase == LoopPhase.VAL:\n",
    "                loss = sigmoid_cross_entropy_loss(nodes_unnormalized_scores, gt_node_labels)\n",
    "            else:\n",
    "                nodes_unnormalized_scores = nodes_unnormalized_scores[:,:-1]\n",
    "                gt_node_labels = gt_node_labels[:,:-1]\n",
    "                loss = sigmoid_cross_entropy_loss(nodes_unnormalized_scores, gt_node_labels)\n",
    "\n",
    "            if phase == LoopPhase.TRAIN:\n",
    "                optimizer.zero_grad()  # clean the trainable weights gradients in the computational graph (.grad fields)\n",
    "                loss.backward()  # compute the gradients for every trainable weight in the computational graph\n",
    "                optimizer.step()  # apply the gradients to weights\n",
    "\n",
    "            # Calculate the main metric - micro F1, check out this link for what micro-F1 exactly is:\n",
    "            # https://www.kaggle.com/enforcer007/what-is-micro-averaged-f1-score\n",
    "\n",
    "            # Convert unnormalized scores into predictions. Explanation:\n",
    "            # If the unnormalized score is bigger than 0 that means that sigmoid would have a value higher than 0.5\n",
    "            # (by sigmoid's definition) and thus we have predicted 1 for that label otherwise we have predicted 0.\n",
    "\n",
    "            \n",
    "            pred = np.full_like(nodes_unnormalized_scores.detach().float().cpu().numpy(), 0)\n",
    "            nusd_dummy = nodes_unnormalized_scores.detach().float().cpu().numpy()\n",
    "            pred[np.arange(len(nusd_dummy)), nusd_dummy.argmax(1)] = 1\n",
    "            gt = gt_node_labels.cpu().numpy()\n",
    "            \n",
    "            if phase == LoopPhase.TEST:\n",
    "                output_index = []\n",
    "                for i in range(np.size(pred, axis = 0)):\n",
    "                    output_index.append(np.argmax(pred[i]))\n",
    "                #print(\"NODE FEATURES : \", node_features)\n",
    "                #print(\"OUTPUT : \", output_index)\n",
    "                #unschedulable = rmrta(node_features, output_index, 31)\n",
    "                \n",
    "                write_node_features = node_features.tolist()\n",
    "                #print(write_node_features)\n",
    "                write_output_index = output_index\n",
    "                with open('./Test/8proc_paper_mixed_features.txt', 'a') as file:\n",
    "                    for row in write_node_features:\n",
    "                        file.write(str(row[0:3]) + '\\n')\n",
    "                with open('./Test/8proc_paper_mixed_features.pkl', 'ab+') as fp:\n",
    "                    pickle.dump(write_node_features, fp)\n",
    "                    \n",
    "                with open('./Test/8proc_paper_mixed_index.txt', 'a') as file:                        \n",
    "                    file.write(str(write_output_index))\n",
    "                with open('./Test/8proc_paper_mixed_index.pkl', 'ab+') as fp:\n",
    "                    pickle.dump(write_output_index, fp)\n",
    "                #print(\"IS IT Unsche ? \", unschedulable)\n",
    "                \n",
    "            micro_f1 = f1_score(gt, pred, average='micro')\n",
    "\n",
    "            #\n",
    "            # Logging\n",
    "            #\n",
    "\n",
    "            global_step = len(data_loader) * epoch + batch_idx\n",
    "            if phase == LoopPhase.TRAIN:\n",
    "                # Log metrics\n",
    "                if config['enable_tensorboard']:\n",
    "                    writer.add_scalar('training_loss', loss.item(), global_step)\n",
    "                    writer.add_scalar('training_micro_f1', micro_f1, global_step)\n",
    "\n",
    "                # Log to console\n",
    "                if config['console_log_freq'] is not None and epoch % config['console_log_freq'] == 0 and batch_idx == 0:\n",
    "                    print(f'GAT training: time elapsed= {(time.time() - time_start):.2f} [s] |'\n",
    "                          f' epoch={epoch + 1} | batch={batch_idx + 1} | train micro-F1={micro_f1}.')\n",
    "\n",
    "                # Save model checkpoint\n",
    "                if config['checkpoint_freq'] is not None and (epoch + 1) % config['checkpoint_freq'] == 0 and batch_idx == 0:\n",
    "                    ckpt_model_name = f'gat_{config[\"dataset_name\"]}_ckpt_epoch_{epoch + 1}.pth'\n",
    "                    config['test_perf'] = -1  # test perf not calculated yet, note: perf means main metric micro-F1 here\n",
    "                    torch.save(get_training_state(config, gat), os.path.join(CHECKPOINTS_PATH, ckpt_model_name))\n",
    "\n",
    "            elif phase == LoopPhase.VAL:\n",
    "                # Log metrics\n",
    "                if config['enable_tensorboard']:\n",
    "                    writer.add_scalar('val_loss', loss.item(), global_step)\n",
    "                    writer.add_scalar('val_micro_f1', micro_f1, global_step)\n",
    "\n",
    "                # Log to console\n",
    "                if config['console_log_freq'] is not None and epoch % config['console_log_freq'] == 0 and batch_idx == 0:\n",
    "                    print(f'GAT validation: time elapsed= {(time.time() - time_start):.2f} [s] |'\n",
    "                          f' epoch={epoch + 1} | batch={batch_idx + 1} | val micro-F1={micro_f1}')\n",
    "\n",
    "                # The \"patience\" logic - should we break out from the training loop? If either validation micro-F1\n",
    "                # keeps going up or the val loss keeps going down we won't stop\n",
    "                if micro_f1 > BEST_VAL_MICRO_F1 or loss.item() < BEST_VAL_LOSS:\n",
    "                    BEST_VAL_MICRO_F1 = max(micro_f1, BEST_VAL_MICRO_F1)  # keep track of the best validation micro_f1 so far\n",
    "                    BEST_VAL_LOSS = min(loss.item(), BEST_VAL_LOSS)  # and the minimal loss\n",
    "                    PATIENCE_CNT = 0  # reset the counter every time we encounter new best micro_f1\n",
    "                else:\n",
    "                    PATIENCE_CNT += 1  # otherwise keep counting\n",
    "\n",
    "                if PATIENCE_CNT >= patience_period:\n",
    "                    raise Exception('Stopping the training, the universe has no more patience for this training.')\n",
    "\n",
    "            else:\n",
    "                return micro_f1  # in the case of test phase we just report back the test micro_f1\n",
    "        \n",
    "    return main_loop  # return the decorated function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "c5300add",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "**************************************************\n",
      "Test micro-F1 = 0.2177487118157285\n"
     ]
    }
   ],
   "source": [
    "# Train the graph attention network (GAT)\n",
    "test_gat_rlforrt(get_training_args())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fc8fb3ee",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "PartitionedRT",
   "language": "python",
   "name": "partitionedrt"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
