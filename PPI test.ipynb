{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "dfa03094",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/rtcl/anaconda3/envs/PartitionedRT/lib/python3.8/site-packages/tqdm/auto.py:22: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "# I always like to structure my imports into Python's native libs,\n",
    "# stuff I installed via conda/pip and local file imports (but we don't have those here)\n",
    "\n",
    "import json\n",
    "import os\n",
    "import enum\n",
    "\n",
    "# Visualization related imports\n",
    "import matplotlib.pyplot as plt\n",
    "import networkx as nx\n",
    "from networkx.readwrite import json_graph\n",
    "import igraph as ig\n",
    "\n",
    "# Main computation libraries\n",
    "import numpy as np\n",
    "\n",
    "# Deep learning related imports\n",
    "import torch\n",
    "from torch.utils.data import DataLoader, Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a09de3d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "    Contains constants needed for data loading and visualization.\n",
    "\n",
    "\"\"\"\n",
    "\n",
    "\n",
    "# Supported datasets - only PPI in this notebook\n",
    "class DatasetType(enum.Enum):\n",
    "    PPI = 0\n",
    "\n",
    "    \n",
    "class GraphVisualizationTool(enum.Enum):\n",
    "    IGRAPH = 0\n",
    "\n",
    "\n",
    "# We'll be dumping and reading the data from this directory\n",
    "DATA_DIR_PATH = os.path.join(os.getcwd(), 'data')\n",
    "PPI_PATH = os.path.join(DATA_DIR_PATH, 'ppi')\n",
    "PPI_URL = 'https://data.dgl.ai/dataset/ppi.zip'  # preprocessed PPI data from Deep Graph Library\n",
    "\n",
    "#\n",
    "# PPI specific constants\n",
    "#\n",
    "\n",
    "PPI_NUM_INPUT_FEATURES = 50\n",
    "PPI_NUM_CLASSES = 121"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "64d73c6e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# First let's define this simple function for loading PPI's graph data\n",
    "\n",
    "def json_read(path):\n",
    "    with open(path, 'r') as file:\n",
    "        data = json.load(file)\n",
    "\n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "fde07d0c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_graph_data(training_config, device):\n",
    "    dataset_name = training_config['dataset_name'].lower()\n",
    "    should_visualize = training_config['should_visualize']\n",
    "\n",
    "    if dataset_name == DatasetType.PPI.name.lower():  # Protein-Protein Interaction dataset\n",
    "\n",
    "        # Instead of checking PPI in, I'd rather download it on-the-fly the first time it's needed (lazy execution ^^)\n",
    "        if not os.path.exists(PPI_PATH):  # download the first time this is ran\n",
    "            os.makedirs(PPI_PATH)\n",
    "\n",
    "            # Step 1: Download the ppi.zip (contains the PPI dataset)\n",
    "            zip_tmp_path = os.path.join(PPI_PATH, 'ppi.zip')\n",
    "            download_url_to_file(PPI_URL, zip_tmp_path)\n",
    "\n",
    "            # Step 2: Unzip it\n",
    "            with zipfile.ZipFile(zip_tmp_path) as zf:\n",
    "                zf.extractall(path=PPI_PATH)\n",
    "            print(f'Unzipping to: {PPI_PATH} finished.')\n",
    "\n",
    "            # Step3: Remove the temporary resource file\n",
    "            os.remove(zip_tmp_path)\n",
    "            print(f'Removing tmp file {zip_tmp_path}.')\n",
    "\n",
    "        # Collect train/val/test graphs here\n",
    "        edge_index_list = []\n",
    "        node_features_list = []\n",
    "        node_labels_list = []\n",
    "\n",
    "        # Dynamically determine how many graphs we have per split (avoid using constants when possible)\n",
    "        num_graphs_per_split_cumulative = [0]\n",
    "\n",
    "        # Small optimization \"trick\" since we only need test in the playground.py\n",
    "        splits = ['test'] if training_config['ppi_load_test_only'] else ['train', 'valid', 'test']\n",
    "\n",
    "        for split in splits:\n",
    "            # PPI has 50 features per node, it's a combination of positional gene sets, motif gene sets,\n",
    "            # and immunological signatures - you can treat it as a black box (I personally have a rough understanding)\n",
    "            # shape = (NS, 50) - where NS is the number of (N)odes in the training/val/test (S)plit\n",
    "            # Note: node features are already preprocessed\n",
    "            node_features = np.load(os.path.join(PPI_PATH, f'{split}_feats.npy'))\n",
    "\n",
    "            # PPI has 121 labels and each node can have multiple labels associated (gene ontology stuff)\n",
    "            # SHAPE = (NS, 121)\n",
    "            node_labels = np.load(os.path.join(PPI_PATH, f'{split}_labels.npy'))\n",
    "\n",
    "            # Graph topology stored in a special nodes-links NetworkX format\n",
    "            nodes_links_dict = json_read(os.path.join(PPI_PATH, f'{split}_graph.json'))\n",
    "            # PPI contains undirected graphs with self edges - 20 train graphs, 2 validation graphs and 2 test graphs\n",
    "            # The reason I use a NetworkX's directed graph is because we need to explicitly model both directions\n",
    "            # because of the edge index and the way GAT implementation #3 works\n",
    "            collection_of_graphs = nx.DiGraph(json_graph.node_link_graph(nodes_links_dict))\n",
    "            # For each node in the above collection, ids specify to which graph the node belongs to\n",
    "            graph_ids = np.load(os.path.join(PPI_PATH, F'{split}_graph_id.npy'))\n",
    "            num_graphs_per_split_cumulative.append(num_graphs_per_split_cumulative[-1] + len(np.unique(graph_ids)))\n",
    "\n",
    "            # Split the collection of graphs into separate PPI graphs\n",
    "            for graph_id in range(np.min(graph_ids), np.max(graph_ids) + 1):\n",
    "                mask = graph_ids == graph_id  # find the nodes which belong to the current graph (identified via id)\n",
    "                graph_node_ids = np.asarray(mask).nonzero()[0]\n",
    "                graph = collection_of_graphs.subgraph(graph_node_ids)  # returns the induced subgraph over these nodes\n",
    "                print(f'Loading {split} graph {graph_id} to CPU. '\n",
    "                      f'It has {graph.number_of_nodes()} nodes and {graph.number_of_edges()} edges.')\n",
    "\n",
    "                # shape = (2, E) - where E is the number of edges in the graph\n",
    "                # Note: leaving the tensors on CPU I'll load them to GPU in the training loop on-the-fly as VRAM\n",
    "                # is a scarcer resource than CPU's RAM and the whole PPI dataset can't fit during the training.\n",
    "                edge_index = torch.tensor(list(graph.edges), dtype=torch.long).transpose(0, 1).contiguous()\n",
    "                edge_index = edge_index - edge_index.min()  # bring the edges to [0, num_of_nodes] range\n",
    "                edge_index_list.append(edge_index)\n",
    "                # shape = (N, 50) - where N is the number of nodes in the graph\n",
    "                node_features_list.append(torch.tensor(node_features[mask], dtype=torch.float))\n",
    "                # shape = (N, 121), BCEWithLogitsLoss doesn't require long/int64 so saving some memory by using float32\n",
    "                node_labels_list.append(torch.tensor(node_labels[mask], dtype=torch.float))\n",
    "\n",
    "                if should_visualize:\n",
    "                    plot_in_out_degree_distributions(edge_index.numpy(), graph.number_of_nodes(), dataset_name)\n",
    "                    visualize_graph(edge_index.numpy(), node_labels[mask], dataset_name)\n",
    "        print(edge_index_list[0].shape)\n",
    "        print(edge_index_list[1].shape)\n",
    "        #\n",
    "        # Prepare graph data loaders\n",
    "        #\n",
    "\n",
    "        # Optimization, do a shortcut in case we only need the test data loader\n",
    "        if training_config['ppi_load_test_only']:\n",
    "            data_loader_test = GraphDataLoader(\n",
    "                node_features_list[num_graphs_per_split_cumulative[0]:num_graphs_per_split_cumulative[1]],\n",
    "                node_labels_list[num_graphs_per_split_cumulative[0]:num_graphs_per_split_cumulative[1]],\n",
    "                edge_index_list[num_graphs_per_split_cumulative[0]:num_graphs_per_split_cumulative[1]],\n",
    "                batch_size=training_config['batch_size'],\n",
    "                shuffle=False\n",
    "            )\n",
    "            return data_loader_test\n",
    "        else:\n",
    "\n",
    "            data_loader_train = GraphDataLoader(\n",
    "                node_features_list[num_graphs_per_split_cumulative[0]:num_graphs_per_split_cumulative[1]],\n",
    "                node_labels_list[num_graphs_per_split_cumulative[0]:num_graphs_per_split_cumulative[1]],\n",
    "                edge_index_list[num_graphs_per_split_cumulative[0]:num_graphs_per_split_cumulative[1]],\n",
    "                batch_size=training_config['batch_size'],\n",
    "                shuffle=True\n",
    "            )\n",
    "\n",
    "            data_loader_val = GraphDataLoader(\n",
    "                node_features_list[num_graphs_per_split_cumulative[1]:num_graphs_per_split_cumulative[2]],\n",
    "                node_labels_list[num_graphs_per_split_cumulative[1]:num_graphs_per_split_cumulative[2]],\n",
    "                edge_index_list[num_graphs_per_split_cumulative[1]:num_graphs_per_split_cumulative[2]],\n",
    "                batch_size=training_config['batch_size'],\n",
    "                shuffle=False  # no need to shuffle the validation and test graphs\n",
    "            )\n",
    "\n",
    "            data_loader_test = GraphDataLoader(\n",
    "                node_features_list[num_graphs_per_split_cumulative[2]:num_graphs_per_split_cumulative[3]],\n",
    "                node_labels_list[num_graphs_per_split_cumulative[2]:num_graphs_per_split_cumulative[3]],\n",
    "                edge_index_list[num_graphs_per_split_cumulative[2]:num_graphs_per_split_cumulative[3]],\n",
    "                batch_size=training_config['batch_size'],\n",
    "                shuffle=False\n",
    "            )\n",
    "\n",
    "            return data_loader_train, data_loader_val, data_loader_test\n",
    "    else:\n",
    "        raise Exception(f'{dataset_name} not yet supported.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "dc674da3",
   "metadata": {},
   "outputs": [],
   "source": [
    "class GraphDataLoader(DataLoader):\n",
    "    \"\"\"\n",
    "    When dealing with batches it's always a good idea to inherit from PyTorch's provided classes (Dataset/DataLoader).\n",
    "\n",
    "    \"\"\"\n",
    "    def __init__(self, node_features_list, node_labels_list, edge_index_list, batch_size=1, shuffle=False):\n",
    "        graph_dataset = GraphDataset(node_features_list, node_labels_list, edge_index_list)\n",
    "        # We need to specify a custom collate function, it doesn't work with the default one\n",
    "        super().__init__(graph_dataset, batch_size, shuffle, collate_fn=graph_collate_fn)\n",
    "\n",
    "\n",
    "class GraphDataset(Dataset):\n",
    "    \"\"\"\n",
    "    This one just fetches a single graph from the split when GraphDataLoader \"asks\" it\n",
    "\n",
    "    \"\"\"\n",
    "    def __init__(self, node_features_list, node_labels_list, edge_index_list):\n",
    "        self.node_features_list = node_features_list\n",
    "        self.node_labels_list = node_labels_list\n",
    "        self.edge_index_list = edge_index_list\n",
    "\n",
    "    # 2 interface functions that need to be defined are len and getitem so that DataLoader can do it's magic\n",
    "    def __len__(self):\n",
    "        return len(self.edge_index_list)\n",
    "\n",
    "    def __getitem__(self, idx):  # we just fetch a single graph\n",
    "        return self.node_features_list[idx], self.node_labels_list[idx], self.edge_index_list[idx]\n",
    "\n",
    "\n",
    "def graph_collate_fn(batch):\n",
    "    \"\"\"\n",
    "    The main idea here is to take multiple graphs from PPI as defined by the batch size\n",
    "    and merge them into a single graph with multiple connected components.\n",
    "\n",
    "    It's important to adjust the node ids in edge indices such that they form a consecutive range. Otherwise\n",
    "    the scatter functions in the implementation 3 will fail.\n",
    "\n",
    "    :param batch: contains a list of edge_index, node_features, node_labels tuples (as provided by the GraphDataset)\n",
    "    \"\"\"\n",
    "\n",
    "    edge_index_list = []\n",
    "    node_features_list = []\n",
    "    node_labels_list = []\n",
    "    num_nodes_seen = 0\n",
    "\n",
    "    for features_labels_edge_index_tuple in batch:\n",
    "        # Just collect these into separate lists\n",
    "        node_features_list.append(features_labels_edge_index_tuple[0])\n",
    "        node_labels_list.append(features_labels_edge_index_tuple[1])\n",
    "\n",
    "        edge_index = features_labels_edge_index_tuple[2]  # all of the components are in the [0, N] range\n",
    "        edge_index_list.append(edge_index + num_nodes_seen)  # very important! translate the range of this component\n",
    "        num_nodes_seen += len(features_labels_edge_index_tuple[1])  # update the number of nodes we've seen so far\n",
    "\n",
    "    # Merge the PPI graphs into a single graph with multiple connected components\n",
    "    node_features = torch.cat(node_features_list, 0)\n",
    "    node_labels = torch.cat(node_labels_list, 0)\n",
    "    edge_index = torch.cat(edge_index_list, 1)\n",
    "\n",
    "    return node_features, node_labels, edge_index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "e6903163",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading train graph 1 to CPU. It has 1767 nodes and 34085 edges.\n",
      "Loading train graph 2 to CPU. It has 1377 nodes and 31081 edges.\n",
      "Loading train graph 3 to CPU. It has 2263 nodes and 61907 edges.\n",
      "Loading train graph 4 to CPU. It has 2339 nodes and 67769 edges.\n",
      "Loading train graph 5 to CPU. It has 1578 nodes and 37740 edges.\n",
      "Loading train graph 6 to CPU. It has 1021 nodes and 19237 edges.\n",
      "Loading train graph 7 to CPU. It has 1823 nodes and 46153 edges.\n",
      "Loading train graph 8 to CPU. It has 2488 nodes and 72878 edges.\n",
      "Loading train graph 9 to CPU. It has 591 nodes and 8299 edges.\n",
      "Loading train graph 10 to CPU. It has 3312 nodes and 109510 edges.\n",
      "Loading train graph 11 to CPU. It has 2401 nodes and 66619 edges.\n",
      "Loading train graph 12 to CPU. It has 1878 nodes and 48146 edges.\n",
      "Loading train graph 13 to CPU. It has 1819 nodes and 47587 edges.\n",
      "Loading train graph 14 to CPU. It has 3480 nodes and 110234 edges.\n",
      "Loading train graph 15 to CPU. It has 2794 nodes and 88112 edges.\n",
      "Loading train graph 16 to CPU. It has 2326 nodes and 62188 edges.\n",
      "Loading train graph 17 to CPU. It has 2650 nodes and 79714 edges.\n",
      "Loading train graph 18 to CPU. It has 2815 nodes and 88335 edges.\n",
      "Loading train graph 19 to CPU. It has 3163 nodes and 97321 edges.\n",
      "Loading train graph 20 to CPU. It has 3021 nodes and 94359 edges.\n",
      "Loading valid graph 21 to CPU. It has 3230 nodes and 100676 edges.\n",
      "Loading valid graph 22 to CPU. It has 3284 nodes and 104758 edges.\n",
      "Loading test graph 23 to CPU. It has 3224 nodes and 103872 edges.\n",
      "Loading test graph 24 to CPU. It has 2300 nodes and 63628 edges.\n",
      "torch.Size([2, 34085])\n",
      "torch.Size([2, 31081])\n",
      "********************\n",
      "torch.Size([2339, 50]) torch.float32\n",
      "torch.Size([2339, 121]) torch.float32\n",
      "torch.Size([2, 67769]) torch.int64\n"
     ]
    }
   ],
   "source": [
    "# Let's just define dummy visualization functions for now - just to stop Python interpreter from complaining!\n",
    "# We'll define them in a moment, properly, I swear.\n",
    "\n",
    "def plot_in_out_degree_distributions():\n",
    "    pass\n",
    "\n",
    "def visualize_graph():\n",
    "    pass\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")  # checking whether you have a GPU\n",
    "\n",
    "config = {\n",
    "    'dataset_name': DatasetType.PPI.name,\n",
    "    'should_visualize': False,\n",
    "    'batch_size': 1,\n",
    "    'ppi_load_test_only': False  # small optimization for loading test graphs only, we won't use it here\n",
    "}\n",
    "\n",
    "data_loader_train, data_loader_val, data_loader_test = load_graph_data(config, device)\n",
    "# Let's fetch a single batch from the train graph data loader\n",
    "node_features, node_labels, edge_index = next(iter(data_loader_train))\n",
    "\n",
    "print('*' * 20)\n",
    "print(node_features.shape, node_features.dtype)\n",
    "print(node_labels.shape, node_labels.dtype)\n",
    "print(edge_index.shape, edge_index.dtype)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1fa2e665",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "PartitionedRT",
   "language": "python",
   "name": "partitionedrt"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
